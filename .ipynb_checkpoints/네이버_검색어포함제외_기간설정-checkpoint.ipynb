{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 크롤링할 키워드는 무엇입니까?: 여행\n",
      "2. 포함할 키워드를 입력하세요:(예:국내,국외)국내,국외\n",
      "3. 제외할 키워드를 입력하세요:(예:국내,국외)베트남,필리핀\n",
      "4. 크롤링할 건수는 몇 건입니까?: 28\n",
      "5. 조회를 시작할 날짜를 입력하세요.: (예:20170101)20170101\n",
      "6. 조회를 종료할 날짜를 입력하세요.: (예:20171231)20201231\n",
      "7. txt, csv, xls 파일을 저장할 경로를 입력하세요.(예:c:\\data\\)c:\\data\\\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup     \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "\n",
    "print(\"============================================================================================================\")\n",
    "print(\"연습문제 4-1: 네이버 블로그 크롤러 : 페이지를 변경하면서 크롤링 후 요약 내용 저장하기\")\n",
    "print(\"============================================================================================================\")\n",
    "keyword = input('1. 크롤링할 키워드는 무엇입니까?: ')\n",
    "includeWord = list(input('''2. 포함할 키워드를 입력하세요:(예:국내,국외)''').split(','))\n",
    "exceptWord = list(input('''3. 제외할 키워드를 입력하세요:(예:국내,국외)''').split(','))\n",
    "num = int(input('4. 크롤링할 건수는 몇 건입니까?: '))\n",
    "startDate = input('5. 조회를 시작할 날짜를 입력하세요.: (예:20170101)')\n",
    "endDate = input('6. 조회를 종료할 날짜를 입력하세요.: (예:20171231)')\n",
    "# ft_name = input('7. 검색 결과를 저장할  txt 파일경로와 이름을 지정하세요(예:c:\\\\data\\\\test.txt): ')\n",
    "# fc_name = input('8. 검색 결과를 저장할  csv 파일경로와 이름을 지정하세요(예:c:\\\\data\\\\test.csv): ')\n",
    "# fx_name = input('9. 검색 결과를 저장할  xls 파일경로와 이름을 지정하세요(예:c:\\\\data\\\\test.xls): ')\n",
    "folder = input('7. txt, csv, xls 파일을 저장할 경로를 입력하세요.(예:c:\\data\\)')\n",
    "\n",
    "ft_name = folder + keyword + \".txt\"\n",
    "fc_name = folder + keyword + \".csv\"\n",
    "fx_name = folder + keyword + \".xls\"\n",
    "\n",
    "path = \"C:\\Temp\\chromedriver_win32\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(\"https://www.naver.com\")\n",
    "time.sleep(2)\n",
    "\n",
    "baseUrl = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=\" + keyword\n",
    "includeAndExceptUrl = baseUrl + '+%2B' + '+%2B'.join(includeWord) + '+-' + '+-'.join(exceptWord)\n",
    "periodUrl = includeAndExceptUrl + \"&sm=tab_opt&nso=p%3Afrom\" + startDate + \"to\" + endDate\n",
    "\n",
    "driver.get(periodUrl)\n",
    "\n",
    "time.sleep(2)\n",
    "driver.find_element(By.LINK_TEXT,\"VIEW\").click()\n",
    "\n",
    "time.sleep(2)\n",
    "driver.find_element(By.LINK_TEXT,\"블로그\").click()\n",
    "\n",
    "full_html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(full_html, 'html.parser')\n",
    "\n",
    "content_list = soup.find('ul',class_='lst_total')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open(ft_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = f\n",
    "time.sleep(1)\n",
    "\n",
    "no = 1\n",
    "no2 = []\n",
    "title2 = []\n",
    "date2 = []\n",
    "writer2 = []\n",
    "content2 = []\n",
    "\n",
    "for i in content_list.find_all('li', \"bx\"):\n",
    "    if no <= num:\n",
    "        no2.append(no)\n",
    "        print('번호:',no)\n",
    "\n",
    "        title = i.find('a', 'api_txt_lines total_tit').get_text()\n",
    "        title2.append(title)\n",
    "        print('제목:', title.strip())\n",
    "\n",
    "        date = i.find('span', 'sub_time sub_txt').get_text()\n",
    "        date2.append(date)\n",
    "        print('작성일자:', date.strip())\n",
    "\n",
    "        writer = i.find('a', 'sub_txt sub_name').get_text()\n",
    "        writer2.append(writer)\n",
    "        print('작성자:', writer.strip())\n",
    "        \n",
    "        content = i.find('div', 'api_txt_lines dsc_txt').get_text()\n",
    "        content2.append(content)\n",
    "        print('내용', content.strip())\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n",
    "        no += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['번호'] = no2\n",
    "df['제목'] = title2\n",
    "df['작성일자'] = date2\n",
    "df['작성자'] = writer2\n",
    "df['내용'] = content2\n",
    "\n",
    "df.to_csv(fc_name, encoding=\"utf-8-sig\", index=False)\n",
    "df.to_excel(fx_name, index=False)\n",
    "\n",
    "print(\" 요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
