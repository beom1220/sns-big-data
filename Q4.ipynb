{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================\n",
      "연습문제 7-4. 구글 사이트에서 pdf 파일을 검색하여 수집하는 크롤러\n",
      "============================================================================================================\n",
      "검색어를 입력하세요: 빅데이터pdf\n",
      "크롤링할 개수를 입력하세요: 10\n",
      "3.결과 파일을 저장할 폴더명만 쓰세요(예:c:\\data\\):c:\\data\\\n",
      "url 로딩에 실패했습니다.\n",
      "\n",
      "url 로딩에 실패했습니다.\n",
      "\n",
      "http://kocw-n.xcache.kinxcdn.com/data/document/2020/kmu/baejaekwon0609/12.pdf\n",
      "1번째 PDF 파일 다운로드 완료.\n",
      "https://webzine.tipa.or.kr/tipa/pdf/201909_sub1_2_1.pdf\n",
      "url 로딩에 실패했습니다.\n",
      "\n",
      "https://koreascience.kr/article/JAKO201216735814149.pdf\n",
      "2번째 PDF 파일 다운로드 완료.\n",
      "https://koreascience.or.kr/article/JAKO201313660603630.pdf\n",
      "3번째 PDF 파일 다운로드 완료.\n",
      "https://koreascience.or.kr/article/JAKO201414753131609.pdf\n",
      "4번째 PDF 파일 다운로드 완료.\n",
      "https://cs.kangwon.ac.kr/~ysmoon/courses/2017_1/grad/06.pdf\n",
      "5번째 PDF 파일 다운로드 완료.\n",
      "url 로딩에 실패했습니다.\n",
      "\n",
      "url 로딩에 실패했습니다.\n",
      "\n",
      "http://www.kmooc.kr/asset-v1:SSUk+SSMOOC10K+2018_T2+type@asset+block@_%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C_4%EC%B0%A8_%EC%82%B0%EC%97%85%ED%98%81%EB%AA%85%EA%B3%BC_%EA%B2%BD%EC%98%81%ED%98%81%EC%8B%A0_03%EC%A3%BC%EC%B0%A8.pdf\n",
      "6번째 PDF 파일 다운로드 완료.\n",
      "https://ssl.pstatic.net/imgstock/upload/research/industry/1573091601951.pdf\n",
      "7번째 PDF 파일 다운로드 완료.\n",
      "https://www.cbnu.ac.kr/resource/DATA/board/204/1460685890215gW6Kqa.pdf\n",
      "8번째 PDF 파일 다운로드 완료.\n",
      "https://kr.object.gov-ncloudstorage.com/open-bucket/boards/1617085141169-%E2%98%85(%EC%B5%9C%EC%A2%85)%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%94%8C%EB%9E%AB%ED%8F%BC_%ED%99%9C%EC%9A%A9_%EC%9A%B0%EC%88%98%EC%82%AC%EB%A1%80%EC%A7%91.pdf\n",
      "9번째 PDF 파일 다운로드 완료.\n",
      "https://thewepop.co.kr/img/2020%20%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%9A%B0%EC%88%98%EC%82%AC%EB%A1%80%EC%A7%91.pdf\n",
      "10번째 PDF 파일 다운로드 완료.\n",
      "PDF 파일 다운로드가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdf(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "        \n",
    "print(\"============================================================================================================\")\n",
    "print(\"연습문제 7-4. 구글 사이트에서 pdf 파일을 검색하여 수집하는 크롤러\")\n",
    "print(\"============================================================================================================\")\n",
    "keyword = input(\"검색어를 입력하세요: \")\n",
    "num = int(input(\"크롤링할 개수를 입력하세요: \"))\n",
    "f_dir = input(\"3.결과 파일을 저장할 폴더명만 쓰세요(예:c:\\\\data\\\\):\")\n",
    "# keyword = \"빅데이터\"\n",
    "# num = 30\n",
    "# f_dir = \"c:\\\\data\\\\\"\n",
    "\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s+'-'+keyword)\n",
    "os.chdir(f_dir+s+'-'+keyword)\n",
    "\n",
    "path = \"C:\\Temp\\chromedriver_win32\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(\"http://google.co.kr\")\n",
    "\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_box.send_keys(keyword)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "time.sleep(2)\n",
    "\n",
    "count = 0\n",
    "while count < num:\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        try:\n",
    "            if href.endswith('.pdf'):\n",
    "                print(href)\n",
    "                pdf_url = href\n",
    "                file_name = os.path.join(f_dir + s + '-' + keyword + '\\\\' + str(count) + \".pdf\")\n",
    "                time.sleep(1)\n",
    "                download_pdf(pdf_url, file_name)\n",
    "                print(str(count+1)+\"번째 PDF 파일 다운로드 완료.\")\n",
    "                count += 1\n",
    "                if count >= num:\n",
    "                    break\n",
    "        except:\n",
    "            print(\"url 로딩에 실패했습니다.\\n\")\n",
    "    if count >= num:\n",
    "        break\n",
    "\n",
    "    # 다음 페이지로 이동\n",
    "    next_button = driver.find_element(By.ID, 'pnnext')\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "print(\"PDF 파일 다운로드가 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
